#where 2^(k-1) is simply the number of observations at each level
df = nrow(model)/2*n
#This function will give the effects based on the model you put in.
effect.calc[,2] = sapply(1:ncol(model), function(i) sum(model[,i]*response)/df)
return(effect.calc)
#This states that the given value will be returned by the function
}
A = c(-1,1,-1,1,-1,1,-1,1)
B = c(-1,-1,1,1,-1,-1,1,1)
C = c(-1,-1,-1,-1,1,1,1,1)
AB = A*B
AC = A*C
BC = B*C
ABC = A*B*C
life1 = c(22,32,35,55,44,40,60,39)
life2 = c(31,43,34,47,45,37,50,41)
life3 = c(25,29,50,46,38,36,54,47)
life = c(life1, life2, life3)
block = c(1,2,2,1,2,1,1,2)
k = 3
n = 1
ABC.model = data.frame(A,B,C,AB,AC,BC,ABC)
tool_effect = find.effect(ABC.model, life1, n = n)
tool_effect
con = nrow(tool_effect)
tmp = qqnorm(tool_effect[-con,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(tool_effect[-con,2], datax = TRUE)
text(tmp$x, tmp$y, tool_effect[-con,1], pos = 3, cex = .55)
ABC.model = data.frame(A,B,C,AB,AC,BC,ABC,life1,block)
speed.aov = aov(life1 ~ block + A + B + C + AC,
ABC.model)
summary(speed.aov)
A = rep(c(-1,1,-1,1),4)
B = rep(c(-1,-1,1,1),4)
C = rep(c(-1,-1,-1,-1,1,1,1,1),2)
D = c(rep(c(-1,-1,-1,-1),2), rep(c(1,1,1,1),2))
Yield = c(6.08, 6.04, 6.53, 6.43, 6.31, 6.09,
6.12, 6.36, 6.79, 6.68, 6.73, 6.08,
6.77, 6.38, 6.49, 6.23)
AB = A*B; AC = A*C; AD = A*D; BD = B*D; CD = C*D
ABC = A*B*C; ABD = A*B*D; BCD = B*C*D; ACD = A*C*D
ABCD = A*B*C*D
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,
ABC,ABD,ACD,BCD,ABCD)
isatin_effect = find.effect(ABCD.model, Yield, n = 1)
conf = nrow(isatin_effect)
tmp = qqnorm(isatin_effect[-conf,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(isatin_effect[-conf,2], datax = TRUE)
# Use plot.window to expand the axes
# plot.window(xlim = xlim_range, ylim = ylim_range)
text(tmp$x, tmp$y, isatin_effect[-conf,1], pos = 3, cex = .55)
# myplot <- ggplot(isatin_effect,
#                  aes(sample = rep.0..n...length.model..)) +
#   stat_qq() +
#   stat_qq_line() +
#   xlab("Theoretical Quantiles") +
#   ylab("Sample Quantiles")
#
# x.pnts <- ggplot_build(myplot)$data[[1]]$x
# y.pnts <- ggplot_build(myplot)$data[[1]]$y
#
# offset <- (max(y.pnts) - min(y.pnts)) / 20
#
# myplot +
#     geom_text(label = isatin_effect$colnames.model.,
#               x = x.pnts,
#               y = y.pnts + offset)
block = as.factor(c(0,1,1,0,1,0,0,1,1,0,0,1,0,1,1,0))
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,
ABC,ABD,ACD,BCD,ABCD,Yield,block)
isatin.aov = aov(Yield ~ block + (B + D)^2,
ABCD.model)
summary(isatin.aov)
(block_effect_by_hand =
mean(ABCD.model$Yield[ABCD.model$block == 0]) -
mean(ABCD.model$Yield[ABCD.model$block == 1]))
Yieldbar = sum(ABCD.model$Yield)
(block_sum_of_squares_by_hand =
sum(ABCD.model$Yield[ABCD.model$block == 0])^2/8 +
sum(ABCD.model$Yield[ABCD.model$block == 1])^2/8 -
Yieldbar^2/16)
ABCD.model$Yield = c(25,71,48,45,68,40,60,65,
43,80,25,104,55,86,70,76)
ABCD.model$Yield[block == 1] = ABCD.model$Yield[block == 1] + 20
(block_effect_by_hand =
mean(ABCD.model$Yield[ABCD.model$block == 0]) -
mean(ABCD.model$Yield[ABCD.model$block == 1]))
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,
ABC,ABD,ACD,BCD,ABCD)
Yield = c(25,71,48,45,68,40,60,65,
43,80,25,104,55,86,70,76)
example_effect = find.effect(ABCD.model, Yield, n = 1)
conf = nrow(example_effect)
tmp = qqnorm(example_effect[-conf,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[-conf,2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[-conf,1], pos = 3, cex = .55)
example.aov = aov(Yield ~ block + A+C+D+AC+AD,
ABCD.model)
summary(example.aov)
A = c(-1,1,-1,1,-1,1,-1,1)
B = c(-1,-1,1,1,-1,-1,1,1)
C = c(-1,-1,-1,-1,1,1,1,1)
AB = A*B
AC = A*C
BC = B*C
ABC = A*B*C
life1 = c(22,32,35,55,44,40,60,39)
life2 = c(31,43,34,47,45,37,50,41)
life3 = c(25,29,50,46,38,36,54,47)
life = c(life1, life2, life3)
blocks = as.factor(c(c(0,1,1,0,1,0,0,1),
2+c(0,1,1,0,0,1,1,0),
4+c(0,0,1,1,1,1,0,0)))
rep = as.factor(c(rep(1,8), rep(2,8), rep(3,8)))
(tool = data.frame(A,B,C,AB,AC,BC,ABC,life,blocks,rep))
ABC.model = data.frame(A,B,C,AB,AC,BC,ABC)
tool_effect = find.effect(ABC.model, life, n = 3)
tmp = qqnorm(tool_effect[,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(tool_effect[,2], datax = TRUE)
text(tmp$x, tmp$y, tool_effect[,1], pos = 3, cex = .55)
# tool.aov = aov(life ~ rep + blocks%in%rep + (A+B+C)^2, tool)
tool.aov = aov(life ~ blocks + (A+B+C)^2, tool)
summary(tool.aov)
tool.lm = lm(life ~ blocks + (A+B+C)^2, tool)
summary(tool.lm)
A = c(-1,1,1,-1,1,-1,-1,1)
B = c(-1,1,-1,1,-1,1,-1,1)
C = c(-1,-1,1,1,-1,-1,1,1)
D = c(-1,-1,-1,-1,1,1,1,1)
AB = A*B
AC = A*C
AD = A*D
BC = B*C
BD = B*D
CD = C*D
ABCD = A*B*C*D
responses = c(2.45,2.29,3.39,2.32,2.24,1.69,2.29,2.03)
cc = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,ABCD,responses)
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,ABCD)
example_effect = find.effect(ABCD.model, responses, n = 1)
# since we confounded ABCD, do not plot it
tmp = qqnorm(example_effect[-nrow(example_effect),2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[-nrow(example_effect),2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[-nrow(example_effect),1], pos = 3, cex = .55)
cc.aov = aov(responses ~ A + B + C + D + AC, cc)
summary(cc.aov)
A = c(-1,1,1,-1,1,-1,-1,1,-1,1,1,1)
B = c(-1,1,-1,1,-1,1,-1,1,1,1,1,1)
C = c(-1,-1,1,1,-1,-1,1,1,-1,1,-1,1)
D = c(-1,-1,-1,-1,1,1,1,1,-1,-1,1,1)
AB = A*B
AC = A*C
AD = A*D
BC = B*C
BD = B*D
CD = C*D
ABCD = A*B*C*D
responses = c(2.45,2.29,3.39,2.32,2.24,1.69,2.29,2.03,
2.16,2.44,1.87,2.04)
blocks = as.factor(c(rep(1,8),rep(2,4)))
cc = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,ABCD,responses,blocks)
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,BC,BD,CD,ABCD)
example_effect = find.effect(ABCD.model, responses, n = 1)
tmp = qqnorm(example_effect[,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[,2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[,1], pos = 3, cex = .55)
cc.aov = aov(responses ~ blocks + A + B + C + D + AB + AC + AD, cc)
summary(cc.aov)
A = rep(c(-1,1,-1,1),2)
B = rep(c(-1,-1,1,1),2)
AB = A*B
rate = c(45,100,45,65,75,60,80,96)
filt = data.frame(A,B,AB,rate)
summary(aov(rate ~ A + B + AB, filt))
(eff_A = sum(A*rate)/(2*2^2))
(eff_B = sum(B*rate)/(2*2^2))
(eff_AB = sum(AB*rate)/(2*2^2))
summary(lm(rate ~ A + B + AB, filt))
(data <- data.frame(
A = c(-1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1, -1, 1),
B = c(-1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1),
C = c(-1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1),
D = c(-1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1),
E = c(1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1),
y = c(7.93, 5.56, 5.77, 12.00, 9.17, 3.65, 6.40, 5.69,
8.82, 17.55, 8.87, 8.94, 13.06, 11.49, 6.25, 26.05)
))
data$AB = data$A*data$B
data$AC = data$A*data$C
data$AD = data$A*data$D
data$AE = data$A*data$E
data$BC = data$B*data$C
data$BD = data$B*data$D
data$BE = data$B*data$E
data$CD = data$C*data$D
data$CE = data$C*data$E
data$DE = data$D*data$E
example_effect = find.effect(subset(data, select = -y), data$y, n = 1)
tmp = qqnorm(example_effect[,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[,2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[,1], pos = 3, cex = .55)
x.aov = aov(y ~ .-(BD+CE+AC), data)
summary(x.aov)
data <- data.frame(
Apatite = factor(c(30, 30, 60, 60, 30, 30, 60, 60,
30, 30, 60, 60, 30, 30, 60, 60)),
pH = factor(c(5, 5, 5, 5, 7, 7, 7, 7, 5, 5, 5, 5, 7, 7, 7, 7)),
Pb = factor(c(0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48, 0.48,
2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41, 2.41)),
Diet = factor(c("Fishbone", "Fishbone", "Hydroxyapatite", "Hydroxyapatite",
"Hydroxyapatite", "Hydroxyapatite", "Fishbone", "Fishbone",
"Hydroxyapatite", "Hydroxyapatite", "Fishbone", "Fishbone",
"Fishbone", "Fishbone", "Hydroxyapatite", "Hydroxyapatite")),
Pb_Response_mM = c(0.05, 0.05, 0.03, 0.05, 0, 0, 0.01, 0,
1.34, 1.26, 1.11, 1.04, 2.11, 2.18, 0.11, 0.12),
pH_Response = c(4.50, 4.74, 3.36, 3.24, 5.53, 5.43, 6.84, 6.61,
2.82, 2.79, 3.35, 3.34, 5.29, 5.06, 3.49, 3.46)
)
data
for(i in 1:4){
levels(data[,i]) <- c(-1,1)
}
data2 = data[c(T,F),]; rownames(data2) <- 1:nrow(data2)
data2
A = as.integer(data2$Apatite)
B = as.integer(data2$pH)
C = as.integer(data2$Pb)
D = as.integer(data2$Diet)
AB = A*B
AC = A*C
AD = A*D
BC = B*C
BD = B*D
CD = C*D
ABC = A*B*C
ABD = A*B*D
ACD = A*C*D
BCD = B*C*D
ABCD = A*B*C*D
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,ABCD)
# First looking at Pb_Response
example_effect = find.effect(ABCD.model, data2$Pb_Response_mM,
n = 1)
conf = nrow(example_effect)
tmp = qqnorm(example_effect[-conf,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[-conf,2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[-conf,1], pos = 3, cex = .55)
data3 = data2
colnames(data3) = c("A","B","C",colnames(data2)[-(1:3)])
fish.aov = lm(Pb_Response_mM ~ A+C, data3)
summary(fish.aov)
data3 = data2
colnames(data3) = c("A","B","C",colnames(data2)[-(1:3)])
fish.aov = lm(Pb_Response_mM ~ (A+B+C+D)^2, data3)
summary(fish.aov)
data3 = data2
colnames(data3) = c("A","B","C",colnames(data2)[-(1:3)])
fish.aov = aov(Pb_Response_mM ~ (A+B+C+D)^2, data3)
summary(fish.aov)
# First looking at pH_Response
example_effect = find.effect(ABCD.model, data2$pH_Response,
n = 1)
conf = nrow(example_effect)
tmp = qqnorm(example_effect[-conf,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[-conf,2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[-conf,1], pos = 3, cex = .55)
fish.aov = aov(ph_Response ~ A+B+C+D+AD, data3)
data3
fish.aov = aov(pH_Response ~ A+B+C+D+AD, data3)
summary(fish.aov)
fish.aov = aov(pH_Response ~ A+B+C+D+AD, data3)
summary(fish.aov)
A = as.integer(data2$Apatite)
B = as.integer(data2$pH)
C = as.integer(data2$Pb)
D = as.integer(data2$Diet)
AB = A*B
AC = A*C
AD = A*D
BC = B*C
BD = B*D
CD = C*D
ABC = A*B*C
ABD = A*B*D
ACD = A*C*D
BCD = B*C*D
ABCD = A*B*C*D
ABCD.model = data.frame(A,B,C,D,AB,AC,AD,ABCD)
# First looking at Pb_Response
example_effect = find.effect(ABCD.model, data2$Pb_Response_mM,
n = 1)
conf = nrow(example_effect)
tmp = qqnorm(example_effect[-conf,2], main = "Normal Probability Plot",
ylab = "Effects", xlab = "Theoretical Quantiles",
datax = TRUE); qqline(example_effect[-conf,2], datax = TRUE)
text(tmp$x, tmp$y, example_effect[-conf,1], pos = 3, cex = .55)
example_effect
source("~/.active-rstudio-document", echo=TRUE)
method_2 = numeric(k)
method_2
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
all.equal(method_1, method_2, chatGPT_method)
all.equal(method_1, method_2)
all.equal(method_1, chatGPT_method)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
9.93/3.88
load("C:/Users/thema/Dropbox/Research/Vecchia/Paper .RDatas/Simulated_GP_runtimes_train_test.RData")
setwd("C:/Users/thema/Dropbox/Research/VPPE package v2/VPPE/GpGp4RG/GpGp4RG")
devtools::install()
setwd("C:/Users/thema/Dropbox/Research/VPPE package v2/VPPE/RobustGaSPV/RobustGaSPV")
devtools::install()
library(GpGp4RG)
library(RobustGaSPV)
library(tictoc)
library(plotly)
library(rhdf5)
library(dplyr)
library(tidyr)
library(lhs)
library(latex2exp)
library(gridExtra)
# helper function
generate_data <- function(p=4,n=1e3,k=1e2,zeromean="No",train=T,
range.par=c(0.5,0.8,1.2,0.3)){
if(!train){
sim_X = randomLHS(n = n, k = p)
sim_rp = range.par[1:p]
sim_S_v = matern15_scaledim(c(1,sim_rp,0),sim_X)
sim_L = chol(sim_S_v)
sim_y = matrix(0,n,k)
sim_y[,1] = t(sim_L)%*%matrix(rnorm(nrow(sim_X)))
# sim_y[,1] = sin(2*pi*1*col1) + 0.01*rnorm(n)
if(k > 1){
for(loc_i in 2:k){
sim_y[,loc_i] = t(sim_L)%*%matrix(rnorm(nrow(sim_X)))
}
}
inputs = sim_X
zeromean = "No"
if(zeromean == "Yes"){
y = apply(sim_y,2,function(x){x - mean(x)})
}else{
y = sim_y
}
}else{
sim_X = randomLHS(n = 2*n, k = p)
sim_rp = range.par[1:p]
sim_S_v = matern15_scaledim(c(1,sim_rp,0),sim_X)
sim_L = chol(sim_S_v)
sim_y = matrix(0,2*n,k)
sim_y[,1] = t(sim_L)%*%matrix(rnorm(nrow(sim_X)))
# sim_y[,1] = sin(2*pi*1*col1) + 0.01*rnorm(n)
if(k > 1){
for(loc_i in 2:k){
sim_y[,loc_i] = t(sim_L)%*%matrix(rnorm(nrow(sim_X)))
}
}
inputs = sim_X
zeromean = "No"
if(zeromean == "Yes"){
y = apply(sim_y,2,function(x){x - mean(x)})
}else{
y = sim_y
}
}
X = inputs
trend = cbind(matrix(1,nrow = nrow(X),ncol = 1), X)
alpha = rep(2,dim(as.matrix(X))[2])
if(!train){
result = list("X"=X,"y"=y,"trend"=trend,"alpha"=alpha,"zeromean"=zeromean)
}else{
result = list("train_X"=X[1:n,],"train_y"=y[1:n,],"train_trend"=trend[1:n,],
"test_X"=X[(n+1):(2*n),],"test_y"=y[(n+1):(2*n),],"test_trend"=trend[(n+1):(2*n),],
"alpha"=alpha,"zeromean"=zeromean)
}
# list2env(result, .GlobalEnv)
return(result)
}
set.seed(05282016)
load_data = F
if(load_data){
load("VPPE_demo.RData")
# removing VPPE runtimes and models
runtimes[2,] = 0
n = c(seq(100,1000,100),seq(1500,4000,500))
VPPE_matrix = vector(mode = "list",length(n)) # object for storing VPPE models
} else {
n = c(seq(100,200,100))
data = vector(mode = "list", length = length(n))
for(i_n in 1:length(n)){
data[[i_n]] = generate_data(p = 4, n = n[i_n], k = 100, zeromean = "No", train = T,
range.par = c(0.5,0.8,1.2,0.3))
}
}
if(!load_data){ # if the data was not loaded above, set up objects needed for figure
kernel_type = 'matern_3_2' # setting the kernel for models to the Matérn 3/2 function
runtimes = matrix(0,2,length(n)) # object for storing PPE and VPPE runtimes (row 1 is PPE)
PPE_matrix = vector(mode = "list",length(n)) # object for storing PPE models
VPPE_matrix = vector(mode = "list",length(n)) # object for storing VPPE models
}
fit_PPE = T
for(i in 1:length(n)){
list2env(data[[i]], .GlobalEnv)
# PPE fitting ---- assign fit_PPE = F to skip this step
if(fit_PPE){
tic()
PPE = ppgasp(train_X,train_y,trend = train_trend, kernel_type = kernel_type, nugget = 0,
nugget.est = T, zero.mean = zeromean)
toc_PPE=toc(log=T)
runtimes[1,i] = as.numeric(toc_PPE$toc-toc_PPE$tic)
PPE_matrix[[i]] = PPE
}
# VPPE fitting
tic()
VPPE = ppgasp(train_X,train_y,trend = train_trend, kernel_type = kernel_type, nugget = 0,
nugget.est = T, zero.mean = zeromean,
vecchia = T, m = 30)
toc_VPPE = toc(log=T)
runtimes[2,i] = as.numeric(toc_VPPE$toc-toc_VPPE$tic)
VPPE_matrix[[i]] = VPPE
}
#----create data frame and put in fitting times----
runtimes_df = data.frame("n" = n, "PPE_times" = runtimes[1,], "VPPE_times" = runtimes[2,])
runtimes_df_long = pivot_longer(runtimes_df, cols = c(PPE_times, VPPE_times),
names_to = "Method", values_to = "Runtime")
#----create a data frame, predict and put in RMSE
RMSE_df = data.frame("n" = n, "PPE_RMSE" = numeric(length(n)), "VPPE_RMSE" = numeric(length(n)))
predict_times_df = data.frame("n" = n, "PPE_pred_time" = numeric(length(n)), "VPPE_pred_time" = numeric(length(n)))
for(i in 1:length(n)){
list2env(data[[i]], .GlobalEnv)
PPE = PPE_matrix[[i]]
VPPE = VPPE_matrix[[i]]
tic()
PPE_predict = predict.ppgasp(PPE, test_X, test_trend)
toc_PPE=toc(log=T)
predict_times_df$PPE_pred_time[i] = as.numeric(toc_PPE$toc-toc_PPE$tic)
tic()
VPPE_predict = predict.ppgasp(VPPE, test_X, test_trend)
toc_VPPE=toc(log=T)
predict_times_df$VPPE_pred_time[i] = as.numeric(toc_VPPE$toc-toc_VPPE$tic)
RMSE_PPE = sqrt(mean((PPE_predict$mean - test_y)^2))
RMSE_VPPE = sqrt(mean((VPPE_predict$mean - test_y)^2))
RMSE_df$PPE_RMSE[i] = RMSE_PPE
RMSE_df$VPPE_RMSE[i] = RMSE_VPPE
cat("Prediction ",i,"/",length(n),"completed.\n")
}
RMSE_df_long = pivot_longer(RMSE_df, cols = c(PPE_RMSE, VPPE_RMSE),
names_to = "Method", values_to = "RMSE")
predict_times_df_long = pivot_longer(predict_times_df, cols = c(PPE_pred_time, VPPE_pred_time),
names_to = "Method", values_to = "pred_time")
df = cbind(runtimes_df_long, RMSE_df_long$RMSE, predict_times_df_long$pred_time)
df = rename(df,all_of(c("RMSE"="RMSE_df_long$RMSE", "pred_times" = "predict_times_df_long$pred_time")))
df$Method <- factor(df$Method,
levels = c("PPE_times", "VPPE_times"),
labels = c("PPE", "VPPE"))
fontsize = 30
fontsize2 = 20
p1 <- ggplot(data=df, aes(x = Runtime, y = RMSE, color = Method)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
scale_x_continuous(trans = "log10", limits = c(min(df$Runtime),1.1e4)) +
scale_y_continuous(trans = "log10", limits = c(1.5e-2,5e-1)) +
labs(x = "Runtime to fit emulator (seconds)", y = "RMSE") +
scale_color_manual(values = c("PPE" = "red", "VPPE" = "blue"),
labels = c("PPE" = "PPE", "VPPE" = "VPPE"),
name = NULL) +
theme_minimal() +
theme(plot.title=element_text(hjust=0.5),
axis.title.x = element_text(size=fontsize),
axis.title.y = element_text(size=fontsize),
axis.text.x = element_text(size=fontsize2),
axis.text.y = element_text(size=fontsize2),
legend.text=element_text(size=fontsize)) +
theme(legend.position = "none")
p2 <- ggplot(data=df, aes(x = n, y = Runtime, color = Method)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
scale_x_continuous(breaks = c(100,seq(500,4000,500)),
labels = c("0.1","0.5","1","1.5","2","2.5","3","3.5","4")) +
scale_y_continuous(trans = "log10", breaks = 10^(0:4), limits = c(0.7,1.5e4)) +
labs(x = TeX("Size of training set ($\\times 10^3$)"), y = "Runtime to fit emulator") +
scale_color_manual(values = c("PPE" = "red", "VPPE" = "blue"),
labels = c("PPE" = "PPE", "VPPE" = "VPPE"),
name = NULL) +
theme_minimal() +
theme(plot.title=element_text(hjust=0.5),
axis.title.x = element_text(size=fontsize),
axis.title.y = element_text(size=fontsize),
axis.text.x = element_text(size=fontsize2),
axis.text.y = element_text(size=fontsize2),
legend.text=element_text(size=fontsize))
p1
p2
